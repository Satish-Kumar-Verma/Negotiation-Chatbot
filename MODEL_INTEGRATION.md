
# How the GPT-3.5-turbo Model Was Integrated

This project integrates OpenAI’s GPT-3.5-turbo model to power the conversation aspect of the negotiation chatbot. Below is a breakdown of how the model is integrated into the project:

## 1. OpenAI API Setup

The OpenAI API is used to access the GPT-3.5-turbo model for generating responses in the negotiation process. To use this API, the following steps were taken:

1. **API Key Setup**: 
   - First, you need an API key from OpenAI. You can sign up and generate an API key [here](https://platform.openai.com/).
   - The API key is then added to the project by replacing `"YOUR_API_KEY"` in the `app.py` file with your actual key.

   ```python
   client = OpenAI(api_key="YOUR_API_KEY")  # Replace with your OpenAI API key
   ```

2. **OpenAI Python Client**:
   - The OpenAI Python client library is installed as a dependency and included in the `requirements.txt` file. This library allows the application to interact with OpenAI’s models.

   ```bash
   pip install openai
   ```

## 2. GPT-3.5-turbo in the Chatbot

The chatbot generates responses using OpenAI’s GPT-3.5-turbo model in the following steps:

1. **Message Structure**:
   - The GPT-3.5-turbo model is accessed via the `client.chat.completions.create()` method, where the user’s message and predefined system instructions are passed as input. The system role defines the behavior of the chatbot, while the user message is passed to simulate the conversation.

   ```python
   def generate_response(prompt):
       response = client.chat.completions.create(
           model="gpt-3.5-turbo",
           messages=[
               {"role": "system", "content": "You are a negotiation bot, handling price discussions strictly."},
               {"role": "user", "content": prompt}
           ]
       )
       return response.choices[0].message.content.strip()
   ```

2. **Prompt Management**:
   - The `generate_response` function formats the input prompt that will be sent to the model. The prompt includes information like the price negotiation logic (e.g., price offers and rejections). Based on this prompt, the GPT-3.5-turbo model generates a conversational response.

3. **Handling Responses**:
   - Once the response is generated by the model, the chatbot returns this response to the user through the API. The response is then processed to provide a natural, conversational reply to the user's input (e.g., accepting, rejecting, or countering an offer).

## 3. GPT-3.5-turbo and Pricing Logic Integration

The GPT-3.5-turbo model is used to create human-like conversation, but the negotiation logic is still controlled within the application. Here’s how the model is integrated with the negotiation logic:

- **Negotiation Logic**: 
   The chatbot evaluates the user’s offer based on predefined rules in the `PricingLogic` class, which checks if the offer is acceptable (within a discount range), too high, or too low.

- **Model Integration**:
   After the pricing logic determines the type of response (accept, reject, or counteroffer), the `generate_response` function is called to create a conversational reply. For example, if the offer is too low, the bot will generate a polite response asking the user to increase the offer.

```python
if status == "accept":
    response_text = f"We accept your offer of ${user_offer}."
elif status == "reject_high":
    response_text = f"Reject: Thank you for your offer, but we cannot accept more than the original price of ${pricing.base_price}. Let's stick with the original price."
elif status == "reject_low":
    response_text = f"Reject: Your offer is too low. Could you increase it to at least ${result}?"

conversation = generate_response(response_text)
```

## 4. Handling Prompt Errors

While the GPT-3.5-turbo model is powerful, it occasionally generates responses that don't strictly follow the pricing logic. This is due to the natural language processing nature of the model. In such cases, using a more advanced model like GPT-4 could improve accuracy.

## 5. Further Customization

Users can easily replace GPT-3.5-turbo with a more advanced model like GPT-4 by changing the `model` parameter in the API call:

```python
response = client.chat.completions.create(
    model="gpt-4",
    messages=[
        {"role": "system", "content": "You are a negotiation bot, handling price discussions strictly."},
        {"role": "user", "content": prompt}
    ]
)
```
